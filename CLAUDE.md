# CLAUDE.md â€” CSF Intelligence Agents
## Codebase snapshot for AI-assisted development

**Last updated:** 2026-02-26
**Repo:** https://github.com/twgonzalez/csf-agents
**Live dashboard:** https://twgonzalez.github.io/csf-agents/

---

## ðŸ”– Next Session Pickup â€” Canva MCP Integration

**Where we left off (2026-02-26):** Exploring Canva MCP to auto-generate social
media graphics directly from the `social_writer.py` image briefs.

**Status:** Canva MCP is registered in `~/.claude.json` but requires a Claude Code
restart + OAuth authentication to activate.

**First thing to do in the next session:**
1. Type `/mcp` in Claude Code to check if Canva MCP shows as connected
2. If not connected: click the OAuth link to authenticate with your Canva account
3. Once authenticated: test by asking Claude to generate Post 1's graphic (see below)

**The test prompt to run once Canva MCP is live:**

> "Using the Canva MCP, create a social media graphic for Instagram (1080x1080).
> Use this as the design brief: deep navy blue background (#1a3a5c), white text,
> gold accent (#c9a227). Headline: [copy headline from outputs/social/social_2026-W08.md Post 1].
> Bill number AB1751 in large gold display type upper-left. Subtext: [copy subtext].
> California Capitol silhouette, faint, lower right. Minimal policy advocacy style."

**The goal:** Determine if Canva's `generate-design` tool can produce a publish-ready
graphic (text + imagery in one pass) or if we need the hybrid approach (AI background
+ manual text in Canva). If quality is good â†’ wire a `--canva` flag into `social_writer.py`
that auto-generates graphics after writing posts.

**Key context on Canva MCP tiers:**
- `generate-design` (AI design from prompt) â†’ works on Pro accounts
- Template autofill (pre-built CSF template + Claude fills fields) â†’ requires Enterprise
- Brand Kit (auto-apply CSF navy/gold/fonts) â†’ Pro or Enterprise
- Start with `generate-design` â€” if quality is there, no template/Enterprise needed

**MCP config added to:** `~/.claude.json` â†’ `mcpServers.canva`
```json
{ "type": "http", "url": "https://mcp.canva.com/mcp" }
```

---

## What This System Does

Multi-agent Python system for the **California Stewardship Fund (CSF)** â€” a conservative-leaning policy organization whose core belief is that **the best decisions come from people closest to them (local control)**. The system monitors California housing legislation and assesses bills for their risk to local government authority.

**Five active agents:**
1. **`agents/legislative/`** â€” Tracks 124+ CA housing bills weekly via LegiScan, detects new bills and status changes, generates markdown reports and HTML email digests
2. **`agents/housing_analyzer/`** â€” Analyzes bills against CSF's 4-criterion local control risk framework using Claude (Anthropic API); stores results back into `tracked_bills.json`; retries transient API errors with exponential backoff (up to 5 attempts, 5 sâ†’120 s)
3. **`agents/newsletter/`** â€” Reads analyzed bill data and uses Claude to write the weekly "Local Control Intelligence" stakeholder newsletter (HTML email, prose-first, editorial voice)
4. **`agents/media/`** â€” Scans RSS feeds (CalMatters, Capitol Weekly, Google News) + optionally NewsAPI and X API (stub) for CA housing coverage; stores results in `data/media/media_digest.json` for downstream agents
5. **`agents/social/`** â€” Reads analyzed bill data + media digest and uses Claude to generate 3 news-aware social media posts per week (X, Facebook, Instagram variants + image briefs); outputs to `outputs/social/`

**Pipeline:**
```
bill_tracker.py â†’ tracked_bills.json â†’ housing_analyzer.py â†’ newsletter_writer.py
                                                           â†˜
                                     media_scanner.py â”€â”€â†’ social_writer.py
```

**Automation:** GitHub Actions (`weekly_tracker.yml`) runs every Monday at 6 AM PT, pulls fresh LegiScan data, commits updated `tracked_bills.json` + `docs/index.html`, and emails the digest.

---

## Project Structure

```
csf-agents/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ legislative/
â”‚   â”‚   â”œâ”€â”€ bill_tracker.py        # Main tracker agent â€” fetch/process/store/report
â”‚   â”‚   â”œâ”€â”€ email_sender.py        # HTML email + GitHub Pages status page builder
â”‚   â”‚   â””â”€â”€ config.yaml            # Keywords, lookback window, paths, SMTP settings
â”‚   â”œâ”€â”€ housing_analyzer/
â”‚   â”‚   â”œâ”€â”€ housing_analyzer.py    # Claude-powered bill risk analyzer
â”‚   â”‚   â””â”€â”€ config.yaml            # Model, paths, logging
â”‚   â”œâ”€â”€ newsletter/
â”‚   â”‚   â”œâ”€â”€ newsletter_writer.py   # Claude-powered newsletter generator
â”‚   â”‚   â”œâ”€â”€ config.yaml            # Model, audience config, email settings
â”‚   â”‚   â””â”€â”€ SPEC.md                # Full technical + content spec
â”‚   â”œâ”€â”€ media/
â”‚   â”‚   â”œâ”€â”€ media_scanner.py       # RSS + NewsAPI + X API stub news scanner
â”‚   â”‚   â””â”€â”€ config.yaml            # Feeds, keywords, API settings, X stub config
â”‚   â”œâ”€â”€ social/
â”‚   â”‚   â”œâ”€â”€ social_writer.py       # Claude-powered social media content generator
â”‚   â”‚   â”œâ”€â”€ config.yaml            # Model, platform settings, brand colors, default voice
â”‚   â”‚   â””â”€â”€ voices/                # Voice files â€” edit these to change tone/framing
â”‚   â”‚       â”œâ”€â”€ default.md         # General CSF voice (Exposeâ†’Outrageâ†’Activateâ†’Change)
â”‚   â”‚       â”œâ”€â”€ urgent.md          # Hearing imminent / time-critical action
â”‚   â”‚       â””â”€â”€ coalition.md       # Peer-to-peer, partner/org-facing messaging
â”‚   â””â”€â”€ shared/
â”‚       â””â”€â”€ utils.py               # HTTP client, logging helpers
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bills/
â”‚   â”‚   â””â”€â”€ tracked_bills.json     # Single source of truth â€” all 125 bills + analysis
â”‚   â””â”€â”€ media/
â”‚       â””â”€â”€ media_digest.json      # Weekly news scan output (auto-generated)
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ index.html                 # GitHub Pages status dashboard (auto-generated)
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ analysis/                  # housing_analyzer markdown reports
â”‚   â”œâ”€â”€ weekly_reports/            # bill_tracker markdown weekly digests
â”‚   â”œâ”€â”€ newsletter/                # newsletter_writer rendered HTML
â”‚   â””â”€â”€ social/                    # social_writer copy-paste markdown (gitignored pattern)
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ generate_demo_email.py     # Builds demo HTML for stakeholder review
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ weekly_tracker.yml         # GitHub Actions weekly automation
â”‚
â”œâ”€â”€ .env.example                   # Credential template (copy to .env)
â””â”€â”€ requirements.txt
```

---

## The Risk Analysis Framework

### CSF's 4 Criteria (stored in `tracked_bills.json` under `analysis`)

| Key | Label | Color | What it flags |
|-----|-------|-------|---------------|
| `pro_housing_production` | **A â€” Local Control Override** | Red `#c0392b` | State preemption of local zoning/general plans |
| `densification` | **B â€” Removes Discretionary Review** | Orange `#d35400` | Eliminates CEQA, design review, public hearings |
| `reduce_discretion` | **C â€” Mandates Development** | Amber `#c47600` | Forces density/quotas beyond local choice |
| `cost_to_cities` | **D â€” Infrastructure & Capacity Burden** | Purple `#6c3483` | ADU fee caps, improvement condition restrictions, cost-shifting |

### Score levels
- `strong` â€” direct, explicit risk (solid pill badge)
- `moderate` â€” meaningful risk with some conditions (lighter pill badge)
- `indirect` â€” tangential risk (no badge shown, recorded in notes)
- `none` â€” no risk signal

### Current analysis state (as of 2026-02-25)
- **125 bills tracked**, 22 analyzed â€” 103 pending re-analysis (will complete next run with retry fix)
- The 2026-02-25 GitHub Actions run hit Anthropic API 529 overload errors across all 104 pending bills; the new exponential backoff retry logic will recover these next week
- Of the 22 currently analyzed:
  - Criterion A: 17 strong, 22 moderate (from prior local runs)
  - Criterion B: 11 strong, 4 moderate
  - Criterion C: 17 strong, 14 moderate
  - Criterion D: 6 strong, 15 moderate

---

## Bill Data Schema

Every bill in `tracked_bills.json["bills"]` follows this schema:

```json
{
  "bill_number":       "AB1751",
  "session":           "2025-2026",
  "title":             "...",
  "author":            "Wicks",
  "status":            "Enrolled",
  "status_date":       "2026-02-18",
  "introduced_date":   "2026-01-06",
  "last_updated":      "2026-02-23T17:38:05",
  "text_url":          "https://leginfo.legislature.ca.gov/...",
  "summary":           "...",
  "subjects":          ["Housing", "ADU"],
  "committees":        ["Assembly Housing and Community Development Committee"],
  "upcoming_hearings": [{"date": "...", "committee": "...", "location": "..."}],
  "actions":           [{"date": "...", "description": "...", "chamber": "Assembly"}],
  "source":            "legiscan",
  "source_id":         "...",
  "first_seen":        "2026-02-21T10:00:00",
  "analysis": {
    "pro_housing_production": "strong",
    "densification":          "moderate",
    "reduce_discretion":      "indirect",
    "cost_to_cities":         "strong",
    "notes":                  "Technical scoring rationale (1-2 sentences each criterion)",
    "comms_brief":            "Summary sentence.\nâ€¢ Risk 1\nâ€¢ Risk 2\nRecommended: Action",
    "analyzed_date":          "2026-02-23",
    "model":                  "claude-sonnet-4-6"
  }
}
```

**Important:** The `comms_brief` field uses a plain-text structured format parsed by `_render_comms_brief()`:
- Line 1: Summary sentence (bold in email)
- `â€¢ bullet` lines: rendered as a table-based list with red dot
- `Recommended: text` line: rendered as an amber callout box

---

## Email / HTML Architecture

`email_sender.py` builds **inline-styled** HTML only â€” no `<style>` blocks, because Gmail/Outlook strip them.

### Key functions

| Function | Purpose |
|----------|---------|
| `build_and_send_email()` | Public API â€” builds + sends the weekly email digest |
| `build_status_page()` | Builds `docs/index.html` for GitHub Pages |
| `_build_html()` | Assembles the full email HTML (620px wide) |
| `_build_page_html()` | Assembles the full status page HTML (900px wide) |
| `_html_analysis_section()` | Local control risk section â€” stats bar, key bill cards, criterion summary |
| `_html_index_section()` | "All Tracked Bills" table â€” includes Risk column with A/B/C/D pills |
| `_html_stalled_section()` | "Watching â€” No Recent Activity" table â€” includes Risk column |
| `_score_pills()` | Renders colored A/B/C/D pill badges from an `analysis` dict |
| `_render_comms_brief()` | Parses plain-text comms_brief into structured HTML sections |
| `_get_analysis_data()` | Computes ranked analysis stats (high_interest, by_crit, watch_list) |

### Color constants

```python
_COLOR_TEAL       = "#b03a2e"   # Risk red â€” section headers, bill links
_COLOR_TEAL_LIGHT = "#fadbd8"   # Light pink â€” section borders, backgrounds
_COLOR_ACCENT     = "#1a5276"   # Deep navy â€” primary heading color
_COLOR_GREEN      = "#1e8449"   # New bill badge
_COLOR_ORANGE     = "#d35400"   # Changed badge / watch list

# Criterion colors
_CRIT_STRONG_BG  = {A: "#c0392b", B: "#d35400", C: "#c47600", D: "#6c3483"}
_CRIT_MODERATE_BG = {A: "#f1948a", B: "#f5cba7", C: "#fad7a0", D: "#d2b4de"}
```

> **Note:** `_COLOR_TEAL` is misnamed â€” it's actually risk red. Renaming is a potential cleanup task. The name was kept to minimize diff surface area during the analysis reframe.

---

## Running Things Locally

### Weekly tracker (full pipeline)
```bash
.venv/bin/python agents/legislative/bill_tracker.py --email
```

### Housing analyzer (re-analyze bills)
```bash
# Analyze only new/changed bills (incremental)
.venv/bin/python agents/housing_analyzer/housing_analyzer.py

# Force re-analyze all 124 bills
.venv/bin/python agents/housing_analyzer/housing_analyzer.py --force

# Analyze a single bill
.venv/bin/python agents/housing_analyzer/housing_analyzer.py --bill AB1751
```

### Regenerate docs/index.html (no email, no data fetch)
```bash
.venv/bin/python - <<'EOF'
import json, sys
from pathlib import Path
from datetime import datetime, timedelta
sys.path.insert(0, ".")
from agents.legislative.email_sender import build_status_page

data = json.loads(Path("data/bills/tracked_bills.json").read_text())
config = {
    "legislative": {"lookback_days": 7, "stalled_days": 7},
    "email": {"include_full_index": True},
    "github": {
        "repo_url": "https://github.com/twgonzalez/csf-agents",
        "pages_url": "https://twgonzalez.github.io/csf-agents/",
    },
}
build_status_page(new_bills=[], changed_bills=[], all_bills=data["bills"],
                  config=config, output_path=Path("docs/index.html"))
print("Done")
EOF
```

### Generate newsletter (Local Control Intelligence)
```bash
# Generate HTML newsletter from real bill data (dry-run, no email sent)
.venv/bin/python agents/newsletter/newsletter_writer.py

# Override lookback window for "new bills" detection
.venv/bin/python agents/newsletter/newsletter_writer.py --lookback 7

# Use a different bill data source
.venv/bin/python agents/newsletter/newsletter_writer.py --bills path/to/tracked_bills.json

# Output: outputs/newsletter/newsletter_YYYY-WNN.html
# Prints subject line + preview text to terminal for use in your send tool
```

### Scan news and social media (media_scanner)
```bash
# Scan all RSS feeds + NewsAPI (if key set), write data/media/media_digest.json
.venv/bin/python agents/media/media_scanner.py

# Preview scan results without writing (dry-run)
.venv/bin/python agents/media/media_scanner.py --dry-run

# Shorter lookback for mid-week refresh
.venv/bin/python agents/media/media_scanner.py --lookback 3

# Output: data/media/media_digest.json
# Sources: CalMatters /housing/, Capitol Weekly, KQED, LAist, Google News (recent)
# Optional (set in .env): NEWSAPI_KEY, X_BEARER_TOKEN
```

### Generate social media content (3 posts Ã— 3 platforms + image briefs)
```bash
# Generate weekly social content with default voice
.venv/bin/python agents/social/social_writer.py

# Use the urgent voice (hearing this week â€” time-critical action)
.venv/bin/python agents/social/social_writer.py --voice urgent

# Use the coalition voice (partner/org-facing messaging)
.venv/bin/python agents/social/social_writer.py --voice coalition

# List all available voices
.venv/bin/python agents/social/social_writer.py --list-voices

# Override lookback window for "new bills" detection
.venv/bin/python agents/social/social_writer.py --lookback 7

# Use a different bill data source
.venv/bin/python agents/social/social_writer.py --bills path/to/tracked_bills.json

# Output (default voice):     outputs/social/social_YYYY-WNN.md + .html
# Output (non-default voice): outputs/social/social_YYYY-WNN_<voice>.md + .html
# Copy-paste ready markdown with X, Facebook, Instagram variants + image briefs

# Voice system â€” to add a new voice for a campaign:
#   1. Create agents/social/voices/<name>.md (plain markdown, no special syntax)
#   2. Run: .venv/bin/python agents/social/social_writer.py --voice <name>
#   No Python code changes required.
```

### Generate stakeholder demo email
```bash
.venv/bin/python scripts/generate_demo_email.py
# Output: outputs/demo_email.html
```

### Local email preview (for any template change)
Use the same script as "Regenerate docs/index.html" above but write to
`outputs/analysis/email_preview_YYYY-MM-DD.html` â€” that path is gitignored.

---

## GitHub CLI Authentication (gh)

**Important for AI-assisted sessions:** `gh` auth does NOT automatically carry over between Claude Code sessions. Always check first; re-auth takes ~30 seconds via device flow.

### Step 1 â€” Check status
```bash
gh auth status
```
- If it shows `âœ“ Logged in to github.com account twgonzalez (keyring)` â†’ you're done.
- If it says "not logged into any GitHub hosts" â†’ proceed to Step 2.

### Step 2 â€” Re-authenticate (device flow)
```bash
gh auth login --hostname github.com --git-protocol https --web
```
This prints a one-time code like `16F3-340B` and a URL. Visit **https://github.com/login/device**, enter the code, and approve. Auth completes automatically and is stored in the macOS keyring for the session.

### What NOT to do
- **Don't** try `gh auth login --with-token` using the credential from `git credential fill` â€” that token (`gho_...`) lacks the `read:org` scope and will fail.
- **Don't** run `gh auth login` in the background (background process can't receive the device flow callback reliably).
- **Don't** try multiple device flow attempts simultaneously â€” old codes expire in ~5 minutes; only the most recent code is valid.

### After auth â€” inspect workflow logs
```bash
gh run list --repo twgonzalez/csf-agents --limit 5
gh run view <run-id> --repo twgonzalez/csf-agents
gh run view --log --job=<job-id> --repo twgonzalez/csf-agents
```

---

## GitHub Actions

**Workflow:** `.github/workflows/weekly_tracker.yml`
**Trigger:** Every Monday 6 AM PT (`cron: '0 14 * * 1'`) + manual `workflow_dispatch`
**Required secrets** (Settings â†’ Secrets and variables â†’ Actions):

| Secret | Purpose |
|--------|---------|
| `LEGISCAN_USER` | legiscan.com login email |
| `LEGISCAN_PASSWORD` | legiscan.com password |
| `LEGISCAN_API_KEY` | LegiScan real-time API key â€” confirmed active as of 2026-02-25 |
| `EMAIL_USER` | Gmail sending address (shared by digest + newsletter) |
| `EMAIL_PASSWORD` | Gmail App Password (16-char) |
| `EMAIL_RECIPIENTS` | Comma-separated recipient list for the weekly digest |
| `ANTHROPIC_API_KEY` | Claude API key (housing analyzer + newsletter writer) |
| `NEWSLETTER_RECIPIENTS` | Comma-separated subscriber list for the newsletter |

**Optional secrets:**

| Secret | Purpose |
|--------|---------|
| `OPENSTATES_API_KEY` | Secondary bill data source (not currently used) |
| `NEWSAPI_KEY` | NewsAPI key â€” adds news article results to media_scanner (free tier sufficient) |
| `X_BEARER_TOKEN` | X API Bearer Token â€” activates social listening in media_scanner (Basic tier $100/mo; stub only until configured) |

**What the workflow commits back:**
- `data/bills/tracked_bills.json` â€” updated bill statuses + new analysis blocks
- `data/media/media_digest.json` â€” weekly news scan results
- `outputs/weekly_reports/` â€” new markdown digest
- `outputs/newsletter/` â€” rendered newsletter HTML
- `outputs/social/` â€” social media posts (.md + .html)
- `docs/index.html` â€” rebuilt GitHub Pages dashboard

> **Merge conflict risk:** If you push analysis changes to `tracked_bills.json` at the same time the Monday workflow runs, you'll get a conflict. Resolution: take the bot's version as base (`git checkout --ours`), then re-inject analysis blocks programmatically (see git history for the merge script pattern).

---

## Known Issues / Tech Debt

1. **`_COLOR_TEAL` misnaming** â€” Constants are named `_COLOR_TEAL` / `_COLOR_TEAL_LIGHT` but are actually risk red/pink since the local control reframe. Safe to rename in a dedicated cleanup PR.

2. **`analysis` blocks survive tracker re-runs** â€” The tracker never touches the `analysis` sub-key, so scores persist. This is intentional but means stale analysis won't auto-update if a bill's scope changes.

3. **Watch list logic uses `cost_to_cities` (Criterion D)** â€” `_get_analysis_data()` defines `watch_list` as bills where D is strong/moderate but total criteria count < 2. If the criteria keys are ever renamed, this hardcoded reference needs updating.

4. **`generate_demo_email.py` uses synthetic bill numbers** â€” Demo bills like "AB 1421" may collide with real bill numbers in future sessions. Demo data is clearly labeled `"source": "demo"`.

---

## Planned Agents (not yet built)

| Agent | Directory | Description |
|-------|-----------|-------------|
| Courts monitor | `agents/courts/` | Housing litigation docket tracker |
| Movement tracker | `agents/movement/` | YIMBY/advocacy group activity |
| Cities monitor | `agents/cities/` | Local government activity |

All agents should follow the same pattern: fetch â†’ process â†’ store (`data/<name>/`) â†’ report (`outputs/`). Use `agents/legislative/` as the template.

**`agents/media/` is now active** â€” see the media scanner section above. Planned upgrades:
- X API activation (when X_BEARER_TOKEN is configured, uncomment stub in `_scan_x_api()`)
- LA Times + Sacramento Bee RSS (currently broken/bot-blocked â€” re-test periodically)
- Newsletter integration: pass `media_digest.json` context to `newsletter_writer.py`
- Reddit scanning (r/california, r/bayarea) â€” free API, good public sentiment signal

---

## Potential Next Features

- **comms_brief editing UI** â€” A lightweight web form to edit/approve AI-generated comms_briefs before they go into the email (currently edit-in-JSON only).
- **Per-criterion filtering** â€” Let email recipients filter the index table by which criteria they care about (requires JavaScript, currently pure server-rendered HTML).
- **Bill detail pages** â€” Instead of linking to leginfo, generate per-bill HTML pages at `docs/bills/AB1751.html` so CSF staff can share a cleaner URL.
- **Historical score tracking** â€” Store analysis score history so changes in risk level over time are visible (e.g., if a bill is amended to remove a preemption provision).
- **Slack/Teams notification** â€” Post the watch list and high-risk summary to a channel instead of / in addition to email.
